#!/usr/bin/env python3

import sys
import os
import json
import errors


def print_help(callable_name, error_info=None):
    if error_info:
        sys.stderr.write(callable_name + ": " + error_info)
    sys.stderr.write("\n")
    sys.stderr.write("Usage: \n")
    sys.stderr.write("\n")
    sys.stderr.write("-h2|--http2\n")
    sys.stderr.write("      The tests ran with HTTP/2.\n")
    sys.stderr.write("\n")
    sys.stderr.write("-h1|--http1\n")
    sys.stderr.write("      The tests ran with HTTP/1.1.\n")
    sys.stderr.write("\n")
    sys.stderr.write("-q|--quic\n")
    sys.stderr.write("      The tests ran with QUIC.\n")
    sys.stderr.write("\n")
    sys.stderr.write("-pq|--proto-quic\n")
    sys.stderr.write("      The tests ran with the QUIC web " +
                     "server proto-quic/Chromium,.\n")
    sys.stderr.write("\n")
    sys.stderr.write("--loss-prob-move-to-gap-dl= " +
                     "/ --loss-prob-move-to-gap-dl=\n")
    sys.stderr.write("      Given in percent. Specify the probability of " +
                     "switching state in the Gilbert-Elliot model of loss " +
                     "rate, for the down-link/up-link  respectively." +
                     " Note: Up-link rarely sees loss in cellular networks. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--loss-rate-burst-dl= / --loss-rate-burst-ul=\n")
    sys.stderr.write("      Given in percent. Specify the loss rate on " +
                     "the down-link/up-link in the burst state " +
                     "(Gilbert-Elliot model see " +
                     "https://en.wikipedia.org/wiki/Burst_error) " +
                     "given in percent. 1-3% on down-link in rare" +
                     "cases but mostly below 1% " +
                     "by an order of magnitude. Up-link rarely " +
                     "sees loss in cellular networks. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--loss-prob-move-burst-dl= /" +
                     "--loss-prob-move-burst-ul=\n")
    sys.stderr.write("      Given in percent. " +
                     "Specify the loss rate on the down-link/up-link " +
                     "in the burst state (Gilbert-Elliot model see " +
                     "https://en.wikipedia.org/wiki/Burst_error) given " +
                     "in percent. 1-3% on down-link in rare cases but " +
                     "mostly below 1% by an order of magnitude. " +
                     "Up-link rarely sees loss in cellular networks. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--delay-dl= / --delay-ul\n")
    sys.stderr.write("      Specify the delay in " +
                     "ms on the down-link/up-link. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--delay-deviation-dl= / " +
                     "--delay-deviation-ul\n")
    sys.stderr.write("      Specify the standard deviation of " +
                     "the delay ms on the down-link/up-link. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--bandwidth-dl= / --bandwidth-ul\n")
    sys.stderr.write("      Specify the bandiwdth in Mbit/s " +
                     "on down-link/up-link\n")
    sys.exit(1)


# Create statistics for a certain type of network-protocol combination
identifiers = {
    "web_protocol": "",
    "loss_rate_burst_ul": "",
    "loss_prob_to_burst_ul": "",
    "loss_prob_to_gap_ul": "",
    "delay_ul": "",
    "deviation_ul": "0.1",
    "bandwidth_ul": "",
    "loss_rate_burst_dl": "",
    "loss_prob_to_burst_dl": "",
    "loss_prob_to_gap_dl": "",
    "delay_dl": "",
    "deviation_dl": "2.5",
    "bandwidth_dl": "",
    "connection_type": "close",
    "trace_mp_ul": "1",
    "trace_mp_dl": "1"
}

# Handle in-arguments
for argument in sys.argv[1:]:
    if argument == "-q" or argument == "--quic":
        identifiers["web_protocol"] = "QUIC"
    elif argument == "-pq" or argument == "--proto-quic":
        identifiers["web_protocol"] = "PROTO-QUIC"
    elif argument == "-h2" or argument == "--http2":
        identifiers["web_protocol"] = "HTTP2"
    elif argument == "-h1" or argument == "--http1":
        identifiers["web_protocol"] = "HTTP"
    elif "--loss-prob-move-to-gap-dl=" in argument:
        identifiers["loss_prob_to_gap_dl"] = \
            argument.replace("--loss-prob-move-to-gap-dl=", "")
    elif "--loss-prob-move-to-burst-dl=" in argument:
        identifiers["loss_prob_to_burst_dl"] = \
            argument.replace("--loss-prob-move-to-burst-dl=", "")
    elif "--loss-rate-burst-dl=" in argument:
        identifiers["loss_rate_burst_dl"] = \
            argument.replace("--loss-rate-burst-dl=", "")
    elif "--loss-prob-move-to-burst-ul=" in argument:
        identifiers["loss_prob_to_burst_ul"] = \
            argument.replace("--loss-prob-move-to-burst-ul=", "")
    elif "--loss-prob-move-to-gap-ul=" in argument:
        identifiers["loss_prob_to_gap_ul"] = \
            argument.replace("--loss-prob-move-to-gap-ul=", "")
    elif "--loss-rate-burst-ul=" in argument:
        identifiers["loss_rate_burst_ul"] = \
            argument.replace("--loss-rate-burst-ul=", "")
    elif "--delay-ul=" in argument:
        identifiers["delay_ul"] = \
            argument.replace("--delay-ul=", "")
    elif "--delay-dl=" in argument:
        identifiers["delay_dl"] = \
            argument.replace("--delay-dl=", "")
    elif "--delay-deviation-ul=" in argument:
        identifiers["deviation_ul"] = \
            argument.replace("--delay-deviation-ul=", "")
    elif "--delay-deviation-dl=" in argument:
        identifiers["deviation_dl"] = \
            argument.replace("--delay-deviation-dl=", "")
    elif "--bandwidth-ul=" in argument:
        identifiers["bandwidth_ul"] = \
            argument.replace("--bandwidth-ul=", "")
    elif "--bandwidth-dl=" in argument:
        identifiers["bandwidth_dl"] = \
            argument.replace("--bandwidth-dl=", "")
    elif "--open-connection" in argument:
        identifiers["connection_type"] = "open"
    elif "--bw-trace=" in argument:
        identifiers["bandwidth_dl"] = "trace"
    elif "--trace-multiplyer-ul=" in argument:
        identifiers["trace_mp_ul"] = \
            argument.replace("--trace-multiplyer-ul=", "")
    elif "--trace-multiplyer-dl=" in argument:
        identifiers["trace_mp_dl"] = \
            argument.replace("--trace-multiplyer-dl=", "")
    else:
        print_help(sys.argv[0], "Invalid argument: " + argument)

# Find the files to read stats from
path_to_statistics = \
    os.path.dirname(os.path.realpath(__file__)) + \
    os.path.sep + \
    ".." + \
    os.path.sep +\
    "logs" + \
    os.path.sep +\
    "hars"
match_string = \
    identifiers["web_protocol"] + \
    "-" + \
    identifiers["connection_type"] + \
    "_bw-"

if identifiers["bandwidth_dl"] == "trace":
    match_string += "trace-" + \
        identifiers["trace_mp_dl"] + \
        "-" + \
        identifiers["trace_mp_ul"]
else:
    match_string += identifiers["bandwidth_dl"] + \
        "-" + \
        identifiers["bandwidth_ul"]

match_string += "_loss-" + \
    identifiers["loss_prob_to_gap_dl"] + \
    "-" + \
    identifiers["loss_prob_to_burst_dl"] + \
    "-" + \
    identifiers["loss_rate_burst_dl"] + \
    "-" + \
    identifiers["loss_prob_to_gap_ul"] + \
    "-" + \
    identifiers["loss_prob_to_burst_ul"] + \
    "-" + \
    identifiers["loss_rate_burst_ul"] + \
    "_dev-" + \
    identifiers["deviation_dl"] + \
    "-" + \
    identifiers["deviation_ul"] + \
    "_" + \
    "delay-" + \
    identifiers["delay_dl"] + \
    "-" + \
    identifiers["delay_ul"] + \
    "_"

matching_folders = []
for folder in os.listdir(path_to_statistics):
    if match_string in folder:
        matching_folders.append(folder)
sys.stderr.write("Matching folders found: \n")
for entry in matching_folders:
    sys.stderr.write(entry + "\n")
# Generate some statistics (finally!)
output_log = dict()
output_log["identifiers"] = identifiers
output_log["stats"] = dict()
output_log["stats"]["failed_urls"] = 0
output_log["stats"]["succeeded_urls"] = 0
output_log["webpages"] = dict()

for folder in matching_folders:
    for har_file in os.listdir(
            path_to_statistics +
            os.path.sep +
            folder):
        if ".har" not in har_file:
            sys.stderr.write(har_file +
                             "does not contain .har, will skip this file.")
            continue

        url = har_file.replace(".har", "")
        if url not in output_log["webpages"]:
            output_log["webpages"][url] = []
        current_stats = {}

        with open(path_to_statistics +
                  os.path.sep +
                  folder +
                  os.path.sep +
                  har_file) as data_file:
            data = None
            try:
                data = json.load(data_file)["log"]
            except json.decoder.JSONDecodeError as e:
                sys.stderr.write("Incorrect json file for url: " + url + "\n")
                sys.stderr.write(str(e) + ": " + e.msg + "\n\n")
                current_stats["status"] = False
                current_stats["error"] = errors.json
                output_log["webpages"][url].append(current_stats)
                continue

            time = None
            try:
                time = max(entry["pageTimings"]["onContentLoad"] \
                    for entry in data["pages"])
            except (KeyError, ValueError) as e:
                current_stats["status"] = False
                current_stats["error"] = errors.url_load
                output_log["webpages"][url].append(current_stats)
                output_log["stats"]["failed_urls"] = \
                    output_log["stats"]["failed_urls"] + 1
                continue
            if not time:
                current_stats["status"] = False
                current_stats["error"] = errors.url_load
                output_log["webpages"][url].append(current_stats)
                output_log["stats"]["failed_urls"] = \
                    output_log["stats"]["failed_urls"] + 1
                continue
            current_stats["time"] = time
            current_stats["resource_count"] = 0
            current_stats["failed_count"] = 0
            current_stats["total_bytes_fetched"] = 0

            for http_pair in data['entries']:
                if "response" in http_pair:
                    response = http_pair["response"]

                    if "status" in response:

                        # Count nr resources fetched
                        if response["status"] == 200:
                            error_key_exist = "_error" in response
                            if error_key_exist is True and \
                              response["_error"] != "":
                                current_stats["failed_count"] += 1
                            else:
                                current_stats["resource_count"] = \
                                    current_stats["resource_count"] + 1

                        # Count the time
                        if type(http_pair["time"]) == "float":
                            current_stats["time"] = \
                                max(
                                    http_pair["time"],
                                    current_stats["time"])
                        # Add resource size to statistics
                        current_stats["total_bytes_fetched"] = \
                            current_stats["total_bytes_fetched"] +\
                            + response["content"]["size"]
                            #response["_transferSize"]
            current_stats["status"] = True
            output_log["webpages"][url].append(current_stats)
            output_log["stats"]["succeeded_urls"] = \
                output_log["stats"]["succeeded_urls"] + 1

sys.stdout.write(json.dumps(output_log))
