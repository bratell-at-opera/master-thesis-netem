#!/usr/bin/env python3

import sys
import os
import json


def print_help(callable_name, error_info=None):
    if error_info:
        sys.stderr.write(callable_name + ": " + error_info)
    sys.stderr.write("\n")
    sys.stderr.write("Usage: \n")
    sys.stderr.write("\n")
    sys.stderr.write("-h2|--http2\n")
    sys.stderr.write("      The tests ran with HTTP/2.\n")
    sys.stderr.write("\n")
    sys.stderr.write("-h1|--http1\n")
    sys.stderr.write("      The tests ran with HTTP/1.1.\n")
    sys.stderr.write("\n")
    sys.stderr.write("-q|--quic\n")
    sys.stderr.write("      The tests ran with QUIC.\n")
    sys.stderr.write("\n")
    sys.stderr.write("--loss-dl= / --loss-ul=\n")
    sys.stderr.write("      Specify the loss rate on the down-link/up-link given in percent. 1-3% on down-link in rare cases but mostly below 1% by an order of magnitude. Up-link rarely sees loss in cellular networks. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--delay-dl= / --delay-ul\n")
    sys.stderr.write("      Specify the delay in ms on the down-link/up-link. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--delay-deviation-dl= / --delay-deviation-ul\n")
    sys.stderr.write("      Specify the standard deviation of the delay ms on the down-link/up-link. \n")
    sys.stderr.write("\n")
    sys.stderr.write("--bandwidth-dl= / --bandwidth-ul\n")
    sys.stderr.write("      Specify the bandiwdth in Mbit/s on down-link/up-link\n")
    sys.exit(1)


# Create statistics for a certain type of network-protocol combination
identifiers = {
    "web_protocol": "",
    "loss_ul": "",
    "delay_ul": "",
    "deviation_ul": "",
    "bandwidth_ul": "",
    "loss_dl": "",
    "delay_dl": "",
    "deviation_dl": "",
    "bandwidth_dl": ""
}

# Handle in-arguments
for argument in sys.argv[1:]:
    if argument == "-q" or argument == "--quic":
        identifiers["web_protocol"] = "QUIC"
    elif argument == "-h2" or argument == "--http2":
        identifiers["web_protocol"] = "HTTP2"
    elif argument == "-h1" or argument == "--http1":
        identifiers["web_protocol"] = "HTTP"
    elif "--loss-ul=" in argument:
        identifiers["loss_ul"] = argument.replace("--loss-ul=", "")
    elif "--loss-dl=" in argument:
        identifiers["loss_dl"] = argument.replace("--loss-dl=", "")
    elif "--delay-ul=" in argument:
        identifiers["delay_ul"] = argument.replace("--delay-ul=", "")
    elif "--delay-dl=" in argument:
        identifiers["delay_dl"] = argument.replace("--delay-dl=", "")
    elif "--delay-deviation-ul=" in argument:
        identifiers["deviation_ul"] = argument.replace("--delay-deviation-ul=", "")
    elif "--delay-deviation-dl=" in argument:
        identifiers["deviation_dl"] = argument.replace("--delay-deviation-dl=", "")
    elif "--bandwidth-ul=" in argument:
        identifiers["bandwidth_ul"] = argument.replace("--bandwidth-ul=", "")
    elif "--bandwidth-dl=" in argument:
        identifiers["bandwidth_dl"] = argument.replace("--bandwidth-dl=", "")
    else:
        print_help(sys.argv[0], "Invalid argument: " + argument)

missing_args = ""
for key, value in identifiers.items():
    if value == "":
        missing_args = missing_args + key + "\n"
if missing_args != "":
    print_help(sys.argv[0], "Forgot to set\n" + missing_args)

# Find the files to read stats from
path_to_statistics = \
    os.path.dirname(os.path.realpath(__file__)) + \
    os.path.sep + \
    ".." + \
    os.path.sep +\
    "logs" + \
    os.path.sep +\
    "hars"
match_string = \
    identifiers["web_protocol"] + \
    "-bw-" + \
    identifiers["bandwidth_dl"] + \
    "-" + \
    identifiers["bandwidth_ul"] + \
    "-loss-" + \
    identifiers["loss_dl"] + \
    "-" + \
    identifiers["loss_ul"] + \
    "-dev-" + \
    identifiers["deviation_dl"] + \
    "-" + \
    identifiers["deviation_ul"] + \
    "-"

matching_folders = []
for folder in os.listdir(path_to_statistics):
    if match_string in folder:
        matching_folders.append(folder)


# Generate some statistics (finally!)
output_log = identifiers
output_log["webpages"] = {}

for folder in matching_folders:
    for har_file in os.listdir(
            path_to_statistics +
            os.path.sep +
            folder):
        if ".har" not in har_file:
            sys.stderr.write(har_file + "does not contain .har, will skip this file.")
            continue

        url = har_file.replace(".har", "")
        if url not in output_log["webpages"]:
            output_log["webpages"][url] = []
        current_stats = {}

        with open(path_to_statistics + os.path.sep + folder + os.path.sep + har_file) as data_file:
            data = None
            try:
                data = json.load(data_file)["log"]
            except json.decoder.JSONDecodeError as e:
                sys.stderr.write("Incorrect json file for url: " + url + "\n")
                sys.stderr.write(str(e) + ": " + e.msg + "\n")
                current_stats["status"] = False
                current_stats["error"] = "Incorrect json file"
                continue
            current_stats["time"] = \
                max(entry["pageTimings"]["onContentLoad"] for entry in data["pages"])
            current_stats["resource_count"] = 0
            current_stats["total_bytes_fetched"] = 0

            for http_pair in data['entries']:
                if "response" in http_pair:
                    response = http_pair["response"]

                    if "status" in response:

                        if response["status"] == 200:
                            # Count nr resources fetched
                            current_stats["resource_count"] = \
                                current_stats["resource_count"] + 1
                            # Count the time
                            if type(http_pair["time"]) == "float":
                                current_stats["time"] = \
                                    max(
                                        http_pair["time"],
                                        current_stats["time"])
                            # Add resource size to statistics
                            current_stats["total_bytes_fetched"] = \
                                current_stats["total_bytes_fetched"] +\
                                response["content"]["size"]
            current_stats["status"] = True
            output_log["webpages"][url].append(current_stats)

print(output_log)
