#!/usr/bin/env python3

import statistics
import sys
import json


data = json.load(sys.stdin)

values = []
nr_urls = 0
urls = []
url_means = []

for url, stats_list in data["webpages"].items():
    nr_urls = nr_urls + 1
    new_values = []
    for stat in stats_list:
        if stat["status"] is True:
            values.append(stat["time"])
            new_values.append(stat["time"])
    urls.append(url)
    if len(new_values) != 0:
        url_means.append(
            statistics.mean(new_values)
            )
    else:
        url_means.append(0)
    values += new_values

median_load_time = statistics.median(values)
max_load_time = max(values)
min_load_time = min(values)
avg_load_time = statistics.mean(values)
deviation = statistics.stdev(values)

url_means.sort()
cdf_scaler = []
y_value = 0
for i in range(0, nr_urls):
    cdf_scaler.append(y_value)
    y_value += 1/float(nr_urls)
print(cdf_scaler)
print(url_means)

print("Avg load time: " + str(avg_load_time))
print("Median load time: " + str(median_load_time))
print("Stddev: " + str(deviation))
print("Max load time: " + str(max_load_time))
print("Min load time: " + str(min_load_time))
print("Different URLs loaded: " + str(nr_urls))
failed = data["stats"]["failed_urls"]
succeeded = data["stats"]["succeeded_urls"]
fail_percentage = \
    100 * \
    (failed / \
     float(failed + succeeded))
print("Nr of tries failed to load: " + str(failed))
print("Nr of tries succeeded to load: " + str(succeeded))
print("Fail percentage = " + str(fail_percentage))

if "--plot" in sys.argv or "-p" in sys.argv:
    from matplotlib.pyplot import figure, clf, plot, xlabel, ylabel, xlim, ylim, title, grid, axes, show
    figure(1)
    plot(url_means, cdf_scaler)
    xlabel('Website')
    ylabel('Average load time')
    title('Average load times')
    grid(True)
    show()
